{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment Name: Tasks 2020 \n",
    "## Course: Machine Learning and Statistics\n",
    "\n",
    "* Student Name: Paul Caulfield\n",
    "* Student No: G00376342\n",
    "\n",
    "* Lecturer: Ian McLoughlin\n",
    "\n",
    "An assignment submitted in part fulfilment of the requirements of the Higher Diploma in Science - Data Analytics: 2020-2021, Galway Mayo Institute of Technology.\n",
    "  * Submitted: 18th December 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "The assessment consistes of four separate tasks. The jupyter notebook contains 4 sections, each section details one of the four tasks which make up the assessment. Below is a brief outline of each of the tasks:\n",
    "\n",
    "* Task 1: I calculate the square root of 2 to 100 decimal places without using any modules from the standard python library or other external library. I outline research conducted in order to develop my algorithm.\n",
    "\n",
    "* Task 2: Using scipy.stats package, I verify the value of the Chi-squared Test published in a Wikipedia article and determine whether the the two categorical variables are independent. \n",
    "\n",
    "* Task 3: Analysis of standard deviation functions used in Excel. I explain which function gives a better estimate for the standard deviation of a population when performed on a sample.\n",
    "  \n",
    "* Task 4: I apply k-means clustering to predict flower species in the Iris Data Set using scikit-learn. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1. Calculate the Square Root of 2 Without Using Any Python Modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Task Summary\n",
    "The objective of this task is to write a Python function called *sqrt2* that calculates and prints to the screen the square root of 2 to 100 decimal places. The function should not depend on any module from the standard python library or other external library. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 The Square Root of 2\n",
    "\n",
    "The square root of 2, expressed as √2, is the positive number that, when multiplied by itself, equals 2 (Wikipedia). Square roots have two roots, one positive and one negative.  The positive root is referred to as the principal square root of 2, so it is not confused with the negative number which is also the square root of 2.\n",
    "\n",
    "Wikipedia states that the square root of 2 is an irrational number. An irrational number, is a number that cannot be expressed as the ratio of two integers. All square roots of natural numbers, other than of perfect squares, are irrational. Perfect squares are the squares of the whole numbers, for example: 1, 4, 9, 16, 25, 36, 49, 64, 81, 100 (Math.com, 2000-2005).\n",
    "\n",
    "The square root of 2 is an irrational number, but it can be expressed as a decimal number. However, there is an infinite number  digits needed to represent the √2 exactly. For this reason, it is common for irrational numbers such as  √2 to be represented as an approximation. Wikipedia states that (≈ 1.4142857) is often used as a good approximation for √2 (Wikipedia).\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Algorithms for Computing the Square Root of 2\n",
    "\n",
    "There is no algorithm that can calculate the √2 exactly, as it is an irrational number with an infinite decimal expansion. As a result, the decimal expansion of √2 can only be computed to a finite-precision approximation. In this task, I will attempt to compute the 100 decimal places using the Babylonian method also known as Newton's Method\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Newton's Method\n",
    "\n",
    "Wikipedia states that Newton's method is the most commonly used algorithm for approximating √2. The method is also known as the Babylonian square-root algorithm or Hero's method. Its origins date back to the Babylonians (c1500 BC). Newton's method, otherwise known as the Newton–Raphson method, is named after Isaac Newton and Joseph Raphson, is an interative algorithm which produces consecutively better approximations to of square roots of natural numbers, other than of perfect squares. \n",
    "\n",
    "![newtons method](images/Newtons.png)\n",
    "\n",
    "\n",
    "The following steps are used to find the square root of a positive number S: (Wiklin, 2016):\n",
    "\n",
    "1. Make an initial estimate, pick a positive number x0.\n",
    "1. Improve the estimate by applying the formula: \n",
    "    * x1 = (x0 + S / x0) / 2. \n",
    "        * x1 is a better approximation to sqrt(S).\n",
    "1. Repeat the above steps until the required decimal expansion converges using the formula:\n",
    "    * xn+1 = (xn + S / xn) / 2 \n",
    "        * Convergence happed when the digits of xn+1 and xn agree.\n",
    "\n",
    "Below is an example of the algorithm adapted from [math.com] showing 10 decimal places which converges after 8 steps.\n",
    "\n",
    "* Step 1: 1. Make an initial guess, to do this first find the two perfect square numbers it lies between.\n",
    "    * 1.4 squared =  1.96 \n",
    "    * 1.5 squared = 2.25\n",
    "    * Therefore the √2 lies between 1.4 and 1.5, so use 1.4 as initial estimate\t\t\t\n",
    "\t\t\t\n",
    "* Step 2. Divide 2 by 1.4\t=\t\t                1.4285714286 (a)\n",
    "\t\t\t\n",
    "* Step 3. Average 1.4 and 1.4828571 (a) = \t\t1.4142857143 (b)\n",
    "\t\t\t\n",
    "* Step 4. Divide 2 by 1.4142857143 (b)  =\t\t\t1.4141414141 (c)\n",
    "\t\t\t\n",
    "* Step 5. Average (b) and (c)           =         1.4142135642 (d)\n",
    "\t\t\t\n",
    "* Step 6. Divide 2 by (d):  \t\t\t  =         1.4142135605 (e)\n",
    "\t\t\t\n",
    "* Step 7. Average (d) and (e)\t\t\t  =         1.4142135624 (f)\n",
    "\t\t\t\n",
    "* Step 8. Divide 2 by (f)   \t\t\t  =         1.4142135624 (g)\n",
    "\t\t\t\n",
    "* Step 9. Average (f) and (g)           =         1.4142135624 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5  SQRT2 Using Newtons Method\n",
    "My first attempt shown below, applied the Newton's method outlined above. While I was able to format the result to 100 decimal places the precision of the answer is not what I was expecting due to a common issue with floating point arithmetic, call representation error.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.4142135623730949234300169337075203657150268554687500000000000000000000000000000000000000000000000000'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Python Function to calculate the square root of 2, adapted from https://www.openbookproject.net/thinkcs/python/english2e/ch06.html\n",
    "\n",
    "def sqrt(x0):\n",
    "    # declare variables\n",
    "    S = float(2) # s = number 2, converted into a float \n",
    "    x0 = float(x0) # initial estimate, converted into a float         \n",
    "    approx = x0\n",
    "    # Improve the estimate by applying the formula x1 = (x0 + S / x0) / 2. \n",
    "    better = (approx + S/approx)/2.0\n",
    "    # Repeat the above steps until the required decimal expansion converges: using (xn+1 = (xn + S / xn) / 2) formula\n",
    "    while better != approx:\n",
    "        approx = better\n",
    "        better = (approx + S/approx)/2.0\n",
    "        result = format(approx, '.100f') # convert result to a string with 100 decimal places\n",
    "    return result\n",
    "    \n",
    "    \n",
    "# Call SQRT Function and pass initial estimate     \n",
    "sqrt(1.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.6 Representation Error\n",
    "\n",
    "The Python Software Foundation states that representation error occurs when \"decimal fractions cannot be represented exactly as binary (base 2) fractions\". As a result, packages such as Python are unable to display the exact decimal expansion. Instead Python will display a decimal approximation to the true decimal value of the binary approximation stored by the machine. Floats are usually approximated \"using a binary fraction with the numerator using the first 53 bits starting with the most significant bit and with the denominator as a power of two\". This is a standard called IEEE-754 floating point arithmetic, Python floats conform to IEEE-754 “double precision” standard. There are some modules in the Python Standard library and stats packages available such as the Decimal Package which get around this limitation. As I am unable to use any of these modules, my research led to the Big Integer Technique, which I outline below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  1.7 SQRT2 Using Big Integer Technique\n",
    "I used the following method to overcome the representation error encountered above. Cross (2019) demonstrates how it is possible to make use Python’s built-in support for big integers to represent high-precision real numbers. He calculated a million digits of Pi, by converting Pi into a big integer, this is possible because unlike floating point numbers, there is no restrictions to the size or precision of integers in Python. \n",
    "\n",
    "To convert a float to a big integer you raise the float to a higher power e.g. to get 100 digitsd in decimal expansion, multiply float by 10 raised to power of 2 x 100 (# of digits precision required).  Cross explains the use of Python’s // operator to perform integer division, otherwise you end up with a floating point result whioch is subject to representation error, as seen earlier.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Square Root of 2 = 1.4142135623730950488016887242096980785696718753769480731766797379907324784621070388503875343276415727\n"
     ]
    }
   ],
   "source": [
    "# Python Function to calculate the square root of 2 using big integer techique\n",
    "# function adapted from https://stackoverflow.com/a/5189881\n",
    "\n",
    "# Function to the big integer square root of s after multiplying by 10 raised to the 2 x digits.\n",
    "def sqrt2(s, digits):\n",
    "    # declare variables\n",
    "    s = s * (10**(2*digits)) # s = number 2, multiplied by 10 raised to the 2 x digits\n",
    "    approx = 0\n",
    "    better = 1 * (10**digits) # initial estimate\n",
    "    # Improve the estimate by applying the formula x1 = (x0 + S / x0) / 2. \n",
    "    while better != approx:\n",
    "        approx = better\n",
    "        # Repeat the above steps until the required decimal expansion converges: using (xn+1 = (xn + S / xn) / 2) formula\n",
    "        #use Python’s // operator to perform integer division (Cross, 2019)\n",
    "        better = (approx + (s // approx)) //2\n",
    "    # format result as a string adapted from https://stackoverflow.com/a/64278569    \n",
    "    print(f'The Square Root of 2 = {better // 10**100}.{better % 10**100:0100d}')\n",
    "    \n",
    "# find the square root of 2, to 100 digits\n",
    "sqrt2(2, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.8 SQRT2 Using Decimal Module\n",
    "I decided to verify the above answer using the python decimal module. The result of which is shown below. The result confirms the same result I got from sqrt2 function above (see 1.7 SQRT2 Using Big Integer Technique). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Square Root of 2 = 1.4142135623730950488016887242096980785696718753769480731766797379907324784621070388503875343276415727\n"
     ]
    }
   ],
   "source": [
    "# Python Function to calculate the square root of 2 using decimal module\n",
    "from decimal import *\n",
    "\n",
    "def sqrtv2(x0): \n",
    "    getcontext().prec = 101\n",
    "    # Change the precision to 100 decimal places: Adapted from https://docs.python.org/3/library/decimal.html\n",
    "    getcontext().rounding = ROUND_DOWN\n",
    "    # Round down the calculation when displaying 100 decimal places.\n",
    "    s = Decimal(2)\n",
    "    x = Decimal(x0) # initial guess\n",
    "    approx = x\n",
    "    # Improve the guess. Apply the formula x1 = (x0 + S / x0) / 2. The number x1 is a better approximation to sqrt(S).\n",
    "    better = (approx + s / approx) / 2\n",
    "    # Repeat the above steps until the required decimal expansion converges: using (xn+1 = (xn + S / xn) / 2) formula\n",
    "    while better != approx:\n",
    "        approx = better           \n",
    "        better = (approx + s / approx ) / 2       \n",
    "         \n",
    "    \n",
    "    print(\"The Square Root of 2 =\", approx)\n",
    "\n",
    "sqrtv2(1.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2 - Chi-squared Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this task, I used scipy.stats package to verify the value of the Chi-squared Test found in the Wikipedia article [11]. The Chi-squared test for independence is a statistical hypothesis test like a t-test. It is used to analyse whether two categorical variables are independent. The Wikipedia article gives the below table as an example [11], stating the Chi-squared value based on it is approximately 24.6 . "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Occupation   | A | B | C | D | Total\n",
    "-------------|---|---|---|---|------\n",
    "White collar | 90| 60|104| 95|\t349 \n",
    "Blue collar\t | 30| 50| 51| 20|\t151\n",
    "No collar\t | 30| 40| 45| 35|\t150\n",
    "-------------|---|---|---|---|------\n",
    "Total\t     |150|150|200|150|\t650"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Brownlee (2019) states that it is common for machine learning to be used to solve classification problems, to determine whether the output variable is dependent or independent of the input variables which are also categorical. If the output variable is found to be independent, then the input variable may removed from the dataset as it is irrelevant to the problem.\n",
    "\n",
    "Pearson’s Chi-Squared Test is commonly used to test pairs of categorical variables for independence. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Pearson’s Chi-Squared Test\n",
    "The Pearson’s Chi-Squared test, is named after Karl Pearson. Wikipedia describes the Chi-Squared test as a \"statistical hypothesis test used to determine whether there is a statistically significant difference between the expected frequencies and the observed frequencies in one or more categories of a contingency table\". \n",
    "\n",
    "A contingency table is a summary of the collected observations, with the columns representing one variable and the rows representing another variable. The count or frequency of observations is recorded in the cells. The output of the test is a statistic, which can be used to determine whether to accept or reject or null hypothesis (H0) that the observed and expected frequencies are the same (Brownlee, 2019).\n",
    "\n",
    "The chi-squared statistic is calculated with the following formula (Hamel, 2018):\n",
    "\n",
    "![statistic](images/chi-squared.png)\n",
    "\n",
    "* *observed is the actual observed count for each category* \n",
    "* *expected is the expected count based on the distribution of the population for the corresponding category* \n",
    "\n",
    "The statistics is usally interpreted as follows (Brownlee 2018):\n",
    "\n",
    "* If statistic >= Critical Value: significant result, reject null hypothesis (H0), dependent.\n",
    "* If statistic < Critical Value: not significant result, fail to reject null hypothesis (H0), independent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Example of Chi-Squared Test (Wikipedia)\n",
    "The Wikipedia article [11], cites the following example: \"Suppose there is a city of 1,000,000 residents with four neighborhoods: A, B, C, and D. A random sample of 650 residents of the city is taken and their occupation is recorded as \"white collar\", \"blue collar\", or \"no collar\". The null hypothesis is that each person's neighborhood of residence is independent of the person's occupational classification.\" The data is represented in the continency table below:\n",
    "\n",
    "Occupation   | A | B | C | D | Total\n",
    "-------------|---|---|---|---|------\n",
    "White collar | 90| 60|104| 95|\t349 \n",
    "Blue collar\t | 30| 50| 51| 20|\t151\n",
    "No collar\t | 30| 40| 45| 35|\t150\n",
    "-------------|---|---|---|---|------\n",
    "Total\t     |150|150|200|150|\t650\n",
    "\n",
    "The Wikipedia article states that the Chi-squared test statistic is approximately 24.6. In the section 2.3 I will use the scipy.stats package to verify the value of this Chi-squared test statistic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Calculate Chi-Squared Test Statistic and *p* Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Import Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>row_totals</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>White Collar</th>\n",
       "      <td>90</td>\n",
       "      <td>60</td>\n",
       "      <td>104</td>\n",
       "      <td>95</td>\n",
       "      <td>349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Blue Collar</th>\n",
       "      <td>30</td>\n",
       "      <td>50</td>\n",
       "      <td>51</td>\n",
       "      <td>20</td>\n",
       "      <td>151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>No Collar</th>\n",
       "      <td>30</td>\n",
       "      <td>40</td>\n",
       "      <td>45</td>\n",
       "      <td>35</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>col_totals</th>\n",
       "      <td>150</td>\n",
       "      <td>150</td>\n",
       "      <td>200</td>\n",
       "      <td>150</td>\n",
       "      <td>650</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                A    B    C    D  row_totals\n",
       "White Collar   90   60  104   95         349\n",
       "Blue Collar    30   50   51   20         151\n",
       "No Collar      30   40   45   35         150\n",
       "col_totals    150  150  200  150         650"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 2: Create Contingency Table (Adapted from Hamel , 2018)\n",
    "\n",
    "# \n",
    "df2 = pd.DataFrame(np.array([[90, 60, 104, 95, 349 ],[30, 50, 51, 20, 151],[30, 40, 45, 35, 150],[150, 150, 200, 150, 650]]),\n",
    "                   columns=['A', 'B', 'C','D', 'row_totals'],index=['White Collar','Blue Collar','No Collar', 'col_totals'])\n",
    "\n",
    "observed = df2.iloc[0:3,0:4]   # Get table without totals for later use\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>White Collar</th>\n",
       "      <td>80.538462</td>\n",
       "      <td>80.538462</td>\n",
       "      <td>107.384615</td>\n",
       "      <td>80.538462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Blue Collar</th>\n",
       "      <td>34.846154</td>\n",
       "      <td>34.846154</td>\n",
       "      <td>46.461538</td>\n",
       "      <td>34.846154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>No Collar</th>\n",
       "      <td>34.615385</td>\n",
       "      <td>34.615385</td>\n",
       "      <td>46.153846</td>\n",
       "      <td>34.615385</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      A          B           C          D\n",
       "White Collar  80.538462  80.538462  107.384615  80.538462\n",
       "Blue Collar   34.846154  34.846154   46.461538  34.846154\n",
       "No Collar     34.615385  34.615385   46.153846  34.615385"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 3: Create Expected Table (Adapted from Hamel , 2018)\n",
    "# expected is the expected count based on the distribution of the population for the corresponding category\n",
    "\n",
    "# to calculate the expected counts for a cell - two steps\n",
    "# 1st: multiply the row total for cell by the column total for cell\n",
    "# 2nd: divide by the total number of observations (650)\n",
    "\n",
    "\n",
    "# get the row & column totals, apply np.outer() function to compute the outer product, then divide by the number of observations:\n",
    "expected =  np.outer(df2[\"row_totals\"][0:3], df2.loc[\"col_totals\"][0:4]) / 650\n",
    "# Place expected counts of each cell in a 2-dimensional table called expected using a pandas dataframe\n",
    "expected = pd.DataFrame(expected)\n",
    "# label columns and rows of table\n",
    "expected.columns = ['A', 'B', 'C','D']\n",
    "expected.index = ['White Collar','Blue Collar','No Collar']\n",
    "# Display expected table\n",
    "expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Statistic is: 24.6\n"
     ]
    }
   ],
   "source": [
    "# Step 4: calculate the chi-square statistic \n",
    "\n",
    "\n",
    "chi_squared_stat = (((observed-expected)**2)/expected).sum().sum()\n",
    "# call .sum() twice: once to get the column sums and a second time to add the column sums together, \n",
    "# returns the sum of the entire 2D table.\n",
    "# Display statistic to 1 place decimals\n",
    "print(f' Statistic is: {chi_squared_stat:.1f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Critical value is : 12.59\n"
     ]
    }
   ],
   "source": [
    "# Step 5: calculate the critical value using scipy.stats\n",
    "\n",
    "# Calculate degrees of freedom (df): as follows 4x3 table so df = 3x2 = 6.\n",
    "\n",
    "# Use scipy.stats ppf function to calculate critical value, by passing confidence level q and degrees of freedom (df)\n",
    "crit = stats.chi2.ppf(q = 0.95, # Find the critical value for 95% confidence*\n",
    "                      df = 6)   # *\n",
    "# Display critical value to 2 places decimals\n",
    "print(f'Critical value is : {crit:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dependent (reject H0)\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Interpret Critical Value adapted from Brownlee 2018\n",
    "\n",
    "if abs(chi_squared_stat) >= crit:\n",
    "\tprint('Dependent (reject H0)') # statistic >= Critical Value: significant result, reject null hypothesis (H0), dependent.\n",
    "else:\n",
    "\tprint('Independent (fail to reject H0)') # statistic < Critical Value: not significant result, fail to reject null hypothesis (H0), independent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P value is : 0.0004098425861096544\n"
     ]
    }
   ],
   "source": [
    "# Step 7: calculate the p value using scipy.stats\n",
    "\n",
    "# use scipy.stats cdf function to calculate p-value, statistic and degrees of freedom (df)\n",
    "p_value = 1 - stats.chi2.cdf(x=chi_squared_stat,  # Find the p-value\n",
    "                             df=6)\n",
    "print(f'P value is : {p_value}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dependent (reject H0)\n"
     ]
    }
   ],
   "source": [
    "# Step 8: Interpret p Value adapted from Brownlee 2018\n",
    "probability = 0.95 # 95% confidence\n",
    "alpha = 1.0 - probability\n",
    "if p_value <= alpha:\n",
    "\tprint('Dependent (reject H0)')\n",
    "else:\n",
    "\tprint('Independent (fail to reject H0)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Verify Chi-Squared Test Statistic\n",
    "\n",
    "The chi-squared statistic which I calculated in step 4 was 24.6 this agrees with the chi-squared statistic published in the Wikipedia article.\n",
    "\n",
    "**Given the chi-squared stat and the high p-value, the test result does not detect a significant relationship between the variables.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3 - Analysis of Standard Deviation Functions used in Excel\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this task is to research excel standard deviation functions and explain which function gives a better estimate for the standard deviation of a population when performed on a sample.\n",
    "  1. In the first part of this task, I explain the difference between the two different versions of the standard deviation calculation found in Microsfot Excel; STDEV.P and STDEV.S. The standard deviation of an array of numbers x is calculated using numpy as np.sqrt(np.sum((x - np.mean(x)) * * 2)/len(x)) .The STDEV.P function performs this calculation but in the STDEV.S calculation the division is by len(x)-1 rather than len(x) . \n",
    "  1. In the second part of this task, I proceed to use numpy to perform a simulation, to demonstrate that the STDEV.S calculation is a better estimate for the standard deviation of a population when performed on a sample. I explain how I arrived at this conclusion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 STDEV.P\n",
    "The STDEV.P function is an Excel function used to calculate the population standard deviation. The function measures how much variance there is in a dataset of numbers compared to the average (mean) of the numbers in the dataset. The STDEV.P function is intended to be used to calculate the standard deviation of all of the elements from a data set. If dataset consists of a sample of the population, then the STDEV.S function should be used instead (Cheusava, 2020).\n",
    "\n",
    "![STDEV.P Formula](images/STDEVP.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 STDEV.S\n",
    "STDEV.S is an Excel function used to calculate the standard deviation of a sample set of data. Standard deviation is a measure of how much variance there is in a sample set of numbers compared to the average (mean) of the sample. It's calulated by getting the square root of; the sum differences between the mean and its data points, squared; divided by the number of data point minus one to correct for bias (Adapted from Hall 2020). This correction for bias is known as Bessel’s Correction, or n-1.\n",
    "\n",
    "According to Wikipedia, Bessel's correction makes use of n − 1 instead of n in the formula for sample standard deviation. This method is used to partially correct the bias in the estimation of the population standard deviation. \n",
    "![STDEV.S Formula](images/STDEVS.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Differences between STDEV.P and STDEV.S\n",
    "\n",
    "STDEV.P | STDEV.S\n",
    "------------ | -------------\n",
    "Data corresponds to the entire population | Data corresponds to a sample of the entire population\n",
    "The standard deviation is calculated using the \"n\" method | The standard deviation is calculated using the \"n-1\" method\n",
    "Does not correct Bias when used on sample of the population | Corrects Bias when used on sample of the entire population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STDEV.P Simulation\n",
    "\n",
    "# Create Dataset - this will simulate entire population of a dataset - adapted from Ebner 2019.\n",
    "\n",
    "# Import NumPy Library as np\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Generate ndarray of \"heights\" drawn from a sample of 10000 random numbers taken from a normal distribution \n",
    "# adapted from https://www.sharpsightlabs.com/blog/numpy-random-normal/\n",
    "\n",
    "# Define paramters\n",
    "loc = 177  # refers to mean adult male height in cms\n",
    "scale = 6.3 # refers to height standard deviation in cms\n",
    "size = 10000 # to generate 10000 values\n",
    "\n",
    "# Create an array using defined parameters using random.normal() function\n",
    "heights = [(np.random.normal(loc, scale , size))]\n",
    "pop = np.random.normal(loc, scale , size)\n",
    "\n",
    "#plot histogram using this data\n",
    "num_bins = 50 #number of bins used for histogram\n",
    "count, bins, ignored = plt.hist(heights, num_bins, density = False) \n",
    "\n",
    "# Plot Parameters\n",
    "plt.style.use('seaborn') # use seaborn theme\n",
    "plt.rcParams['figure.figsize'] = (12, 8) # resize the figure\n",
    "plt.xlabel('Height') # Create Label for x Axis\n",
    "plt.ylabel('Frequency') # Create Label for y Axis\n",
    "\n",
    "# Create Title for Plot - adding annotation for mean and standard deviation\n",
    "plt.title('Histogram of Heights: $\\mu=177.5$, $\\sigma=6.3$')\n",
    "plt.show() # show plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the standard deviation of array 'x' using numpy as np.sqrt(np.sum((x - np.mean(x))**2)/len(x))\n",
    "# Formula: Square root of; the sum differences between the mean and its data points, squared; \n",
    "#                          divided by the number of data points (Adapted from Hall 2020)\n",
    "stdevp = np.sqrt(np.sum((pop - np.mean(pop))**2)/len(pop))\n",
    "print('STDEV.P: ',stdevp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STDEV.S # Simulation 1 - Small Sample\n",
    "\n",
    "# Create random sample from dataset 'pop' to used with STDEV.S Function adapted from Geeksforgeeks 2018 \n",
    "# Generate 50 random integers from dataset 'x'\n",
    "sample1 = np.random.choice(pop,10)\n",
    "print(\"\\n Array 'sample1' filled with sample of 10 random numbers from numpy array 'pop' : \\n\", sample1); # print array "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the standard deviation of array 's' using numpy as np.sqrt(np.sum((x - np.mean(x))**2)/len(x-1))\n",
    "# Formula: Square root of; the sum differences between the mean and its data points, squared; \n",
    "#                          divided by the number of data points…minus one to correct for bias (Adapted from Hall 2020)\n",
    "stdevs = np.sqrt(np.sum((sample1 - np.mean(sample1))**2)/(len(sample1)-1))\n",
    "print('STDEV.S on Small Sample: ', stdevs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare STDEV.P & STDEV.S Simulation 1 - Small Sample\n",
    "\n",
    "# Use sample data and apply STDEV.P formula\n",
    "# Calculate the standard deviation of array 's' using numpy as np.sqrt(np.sum((x - np.mean(x))**2)/len(x))\n",
    "stdevp2 = np.sqrt(np.sum((sample1 - np.mean(sample1))**2)/len(sample1))\n",
    "print('STDEV.P: ',stdevp2,' STDEV.S: ', stdevs, ' Difference: ', stdevs-stdevp2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STDEV.S  Simulation 2 - Large Sample\n",
    "\n",
    "# Create ramdom sample from dataset 'x' to used with STDEV.S Function adapted from Geeksforgeeks 2018 \n",
    "# Generate 200 random integers from dataset 'x'\n",
    "sample2 = np.random.choice(pop,100)\n",
    "print(\"\\n Array 'sample2' filled with sample of 100 random numbers from numpy array 'pop' : \\n\", sample2); # print array  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the standard deviation of array 's2' using numpy as np.sqrt(np.sum((x - np.mean(x))**2)/len(x-1))\n",
    "stdevs2 = np.sqrt(np.sum((sample2 - np.mean(sample2))**2)/(len(sample2)-1))\n",
    "print('STDEV.S on Large Sample: ', stdevs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stdevp = np.sqrt(np.sum((s - np.mean(s))**2)/100)\n",
    "stdevs = np.sqrt(np.sum((s - np.mean(s))**2)/99)\n",
    "print('STDEV.P: ',stdevp,'STDEV.S: ', stdevs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare STDEV.P & STDEV.S Simulation 2 - Large Sample\n",
    "\n",
    "# Use sample data and apply STDEV.P formula\n",
    "# Calculate the standard deviation of array 'sample2' using numpy as np.sqrt(np.sum((x - np.mean(x))**2)/len(x))\n",
    "stdevp3 = np.sqrt(np.sum((sample2 - np.mean(sample2))**2)/len(sample2))\n",
    "print('STDEV.P: ',stdevp3,' STDEV.S: ', stdevs2, ' Difference: ', stdevs2-stdevp3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Conclusions\n",
    "* As the sample size increases the difference between STDEV.P and STDEV.S reduces, when calculated using the same sample dataset.  \n",
    "* In both scenarios the sample standard deviation was greater than the population standard deviation when calculated using the same sample dataset. \n",
    "* Proof that increasing sample size increases standard deviation, which converges to the true population standard deviation. Bessel's correction helps smaller samples get larger standard deviations than they would otherwise, hence n-1.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4 - Apply K-Means Clustering to Predict Flower Species in the Iris Data Set\n",
    "***\n",
    "Using scikit-learn, I apply k-means clustering to Fisher’s famous Iris data set. I explain how my code works and discuss it's accuracy. I go on to outline how my model could be used to make predictions of species of iris.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clustering is an unsupervisedlearning method that allows us to group set of objects based on similar characteristics. In general, it can help you find meaningful structure among your data, group similar data together and discover underlying patterns.\n",
    "\n",
    "One of the most common clustering methods is K-means algorithm. The goal of this algorithm isto partition the data into set such that the total sum of squared distances from each point to the mean point of the cluster is minimized.\n",
    "\n",
    "K means works through the following iterative process:\n",
    "\n",
    "    Pick a value for k (the number of clusters to create)\n",
    "    Initialize k ‘centroids’ (starting points) in your data\n",
    "    Create your clusters. Assign each point to the nearest centroid.\n",
    "    Make your clusters better. Move each centroid to the center of its cluster.\n",
    "    Repeat steps 3–4 until your centroids converge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For interacting with data sets.\n",
    "import pandas as pd\n",
    "\n",
    "# Numerical arrays.\n",
    "import numpy as np\n",
    "\n",
    "# Machine learning - KMeans.\n",
    "import sklearn.cluster as skcl\n",
    "\n",
    "# Plotting.\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import dataset\n",
    "from sklearn import datasets\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the iris data set from the library.\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "X = iris.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your target and predictors.\n",
    "X = iris.data[:, :2] # Select two features to use to predict cluster; sepal length & sepal width\n",
    "y = iris.target # This is the target output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the Data\n",
    "plt.scatter(X[:,0], X[:,1], c=y, cmap='gist_rainbow')\n",
    "plt.xlabel('Sepa1 Length', fontsize=18)\n",
    "plt.ylabel('Sepal Width', fontsize=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick a value for k (the number of clusters to create)\n",
    "km = skcl.KMeans(n_clusters = 3, n_jobs = 4, random_state=21)\n",
    "y_kmeans = km.fit_predict(X)\n",
    "y_kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize k ‘centroids’ (starting points) in your data\n",
    "centers = km.cluster_centers_\n",
    "\n",
    "print(centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualising the clusters\n",
    "\n",
    "plt.scatter(X[y_kmeans == 0, 0], X[y_kmeans == 0, 1], s = 150, c = 'red', label = 'Iris-setosa')\n",
    "plt.scatter(X[y_kmeans == 1, 0], X[y_kmeans == 1, 1], s = 150, c = 'blue', label = 'Iris-versicolour')\n",
    "plt.scatter(X[y_kmeans == 2, 0], X[y_kmeans == 2, 1], s = 150, c = 'green', label = 'Iris-virginica')\n",
    "\n",
    "#Plotting the centroids of the clusters\n",
    "plt.scatter(centers[:, 0], centers[:,1], s = 150, c = 'yellow', label = 'Centroids')\n",
    "\n",
    "plt.legend()\n",
    "plt.xlim([4, 8])\n",
    "plt.ylim([2, 4.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#this will tell us to which cluster does the data observations belong.\n",
    "new_labels = km.labels_# Plot the identified clusters and compare with the answers\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16,8))\n",
    "axes[0].scatter(X[:, 0], X[:, 1], c=y, cmap='gist_rainbow',edgecolor='k', s=150)\n",
    "axes[1].scatter(X[:, 0], X[:, 1], c=new_labels, cmap='jet',edgecolor='k', s=150)\n",
    "axes[0].set_xlabel('Sepal length', fontsize=18)\n",
    "axes[0].set_ylabel('Sepal width', fontsize=18)\n",
    "axes[1].set_xlabel('Sepal length', fontsize=18)\n",
    "axes[1].set_ylabel('Sepal width', fontsize=18)\n",
    "axes[0].tick_params(direction='in', length=10, width=5, colors='k', labelsize=20)\n",
    "axes[1].tick_params(direction='in', length=10, width=5, colors='k', labelsize=20)\n",
    "axes[0].set_title('Actual', fontsize=18)\n",
    "axes[1].set_title('Predicted', fontsize=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References:\n",
    "\n",
    "1. Wikipedia contributors *Square root of 2* [Online] Available at:https://en.wikipedia.org/wiki/Square_root_of_2 [Accessed 6 Oct 2020]\n",
    "1. Wikipedia contributors *Methods of computing square roots* [Online] Available at:https://en.wikipedia.org/wiki/Methods_of_computing_square_roots#Babylonian_method [Accessed 6 Oct 2020]\n",
    "1. Wikipedia contributors *Newton's method* [Online] Available at:https://en.wikipedia.org/wiki/Newton%27s_method [Accessed 6 Oct 2020]\n",
    "1. Wikipedia contributors *Irrational number* [Online] Available at:https://en.wikipedia.org/wiki/Irrational_number [Accessed 6 Oct 2020]\n",
    "1. Wiklin, R (2016) *The Babylonian method for finding square roots by hand* [Online] Available at:https://blogs.sas.com/content/iml/2016/05/16/babylonian-square-roots.html#:~:text=The%20Babylonian%20square%2Droot%20algorithm,Newton%20invented%20his%20general%20procedure. [Accessed 6 Oct 2020]\n",
    "1. Math.com (2012-2020) *Square roots* [Online] Available at:http://www.math.com/school/subject1/lessons/S1U1L9EX.html#sm1 [Accessed 6 Oct 2020]\n",
    "1. Python Software Foundation (2020) *Floating Point Arithmetic: Issues and Limitations* [Online] Available at:https://docs.python.org/3/tutorial/floatingpoint.html [Accessed 16 Oct 2020]\n",
    "1. Cross, D (2019) *How to Calculate a Million Digits of Pi* [Online] Available at:https://medium.com/@cosinekitty/how-to-calculate-a-million-digits-of-pi-d62ce3db8f58 [Accessed 21 Oct 2020]\n",
    "1. Python Software Foundation (2020) *Floating Point Arithmetic: Issues and Limitations* [Online] Available at:https://docs.python.org/3/tutorial/floatingpoint.html [Accessed 16 Oct 2020]\n",
    "1. Elkner, J Downey, A.B. & Meyers, C (2010) *Iteration* [Online] Available at:https://www.openbookproject.net/thinkcs/python/english2e/ch06.html [Accessed 7 Dec 2020]\n",
    "\n",
    "1. Wikipedia contributors *Chi-squared test* [Online] Available at:https://en.wikipedia.org/wiki/Chi-squared_test [Accessed 2 Nov 2020]\n",
    "1. Brownlee, J (2018) *A Gentle Introduction to the Chi-Squared Test for Machine Learning* [Online] Available at:https://machinelearningmastery.com/chi-squared-test-for-machine-learning/ [Accessed 02 Nov 2020]\n",
    "1. Hamel, G, J (2018) *Python for Data 25: Chi-Squared Tests* [Online] Available at:https://www.kaggle.com/hamelg/python-for-data-25-chi-squared-tests [Accessed 02 Nov 2020]\n",
    "1. Bruns, D (2012-2020) *Excel STDEV.S Function* [Online] Available at:https://exceljet.net/excel-functions/excel-stdev.p-function3 [Accessed 23 Nov 2020]\n",
    "1. Cheusava, S (2020) *How to calculate standard deviation in Excel* [Online] Available at:https://www.ablebits.com/office-addins-blog/2017/05/31/calculate-standard-deviation-excel/ [Accessed 23 Nov 2020]\n",
    "1. Ebner, J (2019) *HOW TO USE NUMPY RANDOM NORMAL IN PYTHON* [Online] Available at: https://www.sharpsightlabs.com/blog/numpy-random-normal/  [Accessed 23 Nov 2020]\n",
    "1. Geeksforgeeks (2018) *Python Numbers | choice() function* [Online] Available at:https://www.geeksforgeeks.org/python-numbers-choice-function/ [Accessed 23 Nov 2020]\n",
    "1. Hall, B (2020) *The Reasoning Behind Bessel’s Correction: n-1* [Online] Available at:https://towardsdatascience.com/the-reasoning-behind-bessels-correction-n-1-eeea25ec9bc9 [Accessed 23 Nov 2020]\n",
    "1. Wikipedia contributors (2020) *Bessel's correction* [Online] Available at:https://en.wikipedia.org/wiki/Bessel%27s_correction [Accessed 23 Nov 2020]\n",
    "1. Sanchez, B (2018) *PREDICTING IRIS FLOWER SPECIES WITH K-MEANS CLUSTERING IN PYTHON* [Online] Available at:https://medium.com/@belen.sanchez27/predicting-iris-flower-species-with-k-means-clustering-in-python-f6e46806aaee [Accessed 01 Dec 2020]\n",
    "1. Tim, I (2016) *Simple K-means clustering on the Iris dataset* [Online] Available at:https://www.kaggle.com/tonzowonzo/simple-k-means-clustering-on-the-iris-dataset [Accessed 01 Dec 2020]\n",
    "1. Dua, D. and Graff, C. (2019) UCI Machine Learning Repository *Iris Data Set* [Online] Available at:https://archive.ics.uci.edu/ml/datasets/Iris [Accessed 01 Dec 2020]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
