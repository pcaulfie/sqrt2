{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment Name: Tasks 2020 \n",
    "## Course: Machine Learning and Statistics\n",
    "\n",
    "* Student Name: Paul Caulfield\n",
    "* Student No: G00376342\n",
    "\n",
    "* Lecturer: Ian McLoughlin\n",
    "\n",
    "An assignment submitted in part fulfilment of the requirements of the Higher Diploma in Science - Data Analytics: 2020-2021, Galway Mayo Institute of Technology.\n",
    "  * Submitted: 18th December 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "The assessment consistes of four separate tasks. The jupyter notebook contains 4 sections, each section details one of the four tasks which make up the assessment. Below is a brief outline of each of the tasks:\n",
    "\n",
    "* Task 1: I calculate the square root of 2 to 100 decimal places without using any modules from the standard python library or other external library. I outline research conducted in order to develop my algorithm.\n",
    "\n",
    "* Task 2: Using scipy.stats package, I verify the value of the Chi-squared Test published in a Wikipedia article and determine whether the the two categorical variables are independent. \n",
    "\n",
    "* Task 3: Analysis of standard deviation functions used in Excel. I explain which function gives a better estimate for the standard deviation of a population when performed on a sample.\n",
    "  \n",
    "* Task 4: I apply k-means clustering to predict flower species in the Iris Data Set using scikit-learn. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1. Calculate the Square Root of 2 Without Using Any Python Modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Task Summary\n",
    "The objective of this task is to write a Python function called *sqrt2* that calculates and prints to the screen the square root of 2 to 100 decimal places. The function should not depend on any module from the standard python library or other external library. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 The Square Root of 2\n",
    "\n",
    "The square root of 2, expressed as √2, is the positive number that, when multiplied by itself, equals 2 (Wikipedia). Square roots have two roots, one positive and one negative.  The positive root is referred to as the principal square root of 2, so it is not confused with the negative number which is also the square root of 2.\n",
    "\n",
    "Wikipedia states that the square root of 2 is an irrational number. An irrational number, is a number that cannot be expressed as the ratio of two integers. All square roots of natural numbers, other than of perfect squares, are irrational. Perfect squares are the squares of the whole numbers, for example: 1, 4, 9, 16, 25, 36, 49, 64, 81, 100 (Math.com, 2000-2005).\n",
    "\n",
    "The square root of 2 is an irrational number, but it can be expressed as a decimal number. However, there is an infinite number  digits needed to represent the √2 exactly. For this reason, it is common for irrational numbers such as  √2 to be represented as an approximation. Wikipedia states that (≈ 1.4142857) is often used as a good approximation for √2 (Wikipedia).\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Algorithms for Computing the Square Root of 2\n",
    "\n",
    "There is no algorithm that can calculate the √2 exactly, as it is an irrational number with an infinite decimal expansion. As a result, the decimal expansion of √2 can only be computed to a finite-precision approximation. In this task, I will attempt to compute the 100 decimal places using the Babylonian method also known as Newton's Method\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Newton's Method\n",
    "\n",
    "Wikipedia states that Newton's method is the most commonly used algorithm for approximating √2. The method is also known as the Babylonian square-root algorithm or Hero's method. Its origins date back to the Babylonians (c1500 BC). Newton's method, otherwise known as the Newton–Raphson method, is named after Isaac Newton and Joseph Raphson, is an interative algorithm which produces consecutively better approximations to of square roots of natural numbers, other than of perfect squares. \n",
    "\n",
    "![newtons method](images/Newtons.png)\n",
    "\n",
    "\n",
    "The following steps are used to find the square root of a positive number S: (Wiklin, 2016):\n",
    "\n",
    "1. Make an initial estimate, pick a positive number x0.\n",
    "1. Improve the estimate by applying the formula: \n",
    "    * x1 = (x0 + S / x0) / 2. \n",
    "        * x1 is a better approximation to sqrt(S).\n",
    "1. Repeat the above steps until the required decimal expansion converges using the formula:\n",
    "    * xn+1 = (xn + S / xn) / 2 \n",
    "        * Convergence happed when the digits of xn+1 and xn agree.\n",
    "\n",
    "Below is an example of the algorithm adapted from [math.com] showing 10 decimal places which converges after 8 steps.\n",
    "\n",
    "* Step 1: 1. Make an initial guess, to do this first find the two perfect square numbers it lies between.\n",
    "    * 1.4 squared =  1.96 \n",
    "    * 1.5 squared = 2.25\n",
    "    * Therefore the √2 lies between 1.4 and 1.5, so use 1.4 as initial estimate\t\t\t\n",
    "\t\t\t\n",
    "* Step 2. Divide 2 by 1.4\t=\t\t                1.4285714286 (a)\n",
    "\t\t\t\n",
    "* Step 3. Average 1.4 and 1.4828571 (a) = \t\t1.4142857143 (b)\n",
    "\t\t\t\n",
    "* Step 4. Divide 2 by 1.4142857143 (b)  =\t\t\t1.4141414141 (c)\n",
    "\t\t\t\n",
    "* Step 5. Average (b) and (c)           =         1.4142135642 (d)\n",
    "\t\t\t\n",
    "* Step 6. Divide 2 by (d):  \t\t\t  =         1.4142135605 (e)\n",
    "\t\t\t\n",
    "* Step 7. Average (d) and (e)\t\t\t  =         1.4142135624 (f)\n",
    "\t\t\t\n",
    "* Step 8. Divide 2 by (f)   \t\t\t  =         1.4142135624 (g)\n",
    "\t\t\t\n",
    "* Step 9. Average (f) and (g)           =         1.4142135624 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5  SQRT2 Using Newtons Method\n",
    "My first attempt shown below, applied the Newton's method outlined above. While I was able to format the result to 100 decimal places the precision of the answer is not what I was expecting due to a common issue with floating point arithmetic, call representation error.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.4142135623730949234300169337075203657150268554687500000000000000000000000000000000000000000000000000'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Python Function to calculate the square root of 2, adapted from https://www.openbookproject.net/thinkcs/python/english2e/ch06.html\n",
    "\n",
    "def sqrt(x0):\n",
    "    # declare variables\n",
    "    S = float(2) # s = number 2, converted into a float \n",
    "    x0 = float(x0) # initial estimate, converted into a float         \n",
    "    approx = x0\n",
    "    # Improve the estimate by applying the formula x1 = (x0 + S / x0) / 2. \n",
    "    better = (approx + S/approx)/2.0\n",
    "    # Repeat the above steps until the required decimal expansion converges: using (xn+1 = (xn + S / xn) / 2) formula\n",
    "    while better != approx:\n",
    "        approx = better\n",
    "        better = (approx + S/approx)/2.0\n",
    "        result = format(approx, '.100f') # convert result to a string with 100 decimal places\n",
    "    return result\n",
    "    \n",
    "    \n",
    "# Call SQRT Function and pass initial estimate     \n",
    "sqrt(1.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.6 Representation Error\n",
    "\n",
    "The Python Software Foundation states that representation error occurs when \"decimal fractions cannot be represented exactly as binary (base 2) fractions\". As a result, packages such as Python are unable to display the exact decimal expansion. Instead Python will display a decimal approximation to the true decimal value of the binary approximation stored by the machine. Floats are usually approximated \"using a binary fraction with the numerator using the first 53 bits starting with the most significant bit and with the denominator as a power of two\". This is a standard called IEEE-754 floating point arithmetic, Python floats conform to IEEE-754 “double precision” standard. There are some modules in the Python Standard library and stats packages available such as the Decimal Package which get around this limitation. As I am unable to use any of these modules, my research led to the Big Integer Technique, which I outline below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  1.7 SQRT2 Using Big Integer Technique\n",
    "I used the following method to overcome the representation error encountered above. Cross (2019) demonstrates how it is possible to make use Python’s built-in support for big integers to represent high-precision real numbers. He calculated a million digits of Pi, by converting Pi into a big integer, this is possible because unlike floating point numbers, there is no restrictions to the size or precision of integers in Python. \n",
    "\n",
    "To convert a float to a big integer you raise the float to a higher power e.g. to get 100 digitsd in decimal expansion, multiply float by 10 raised to power of 2 x 100 (# of digits precision required).  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Square Root of 2 = 1.4142135623730950488016887242096980785696718753769480731766797379907324784621070388503875343276415727\n"
     ]
    }
   ],
   "source": [
    "# Python Function to calculate the square root of 2 using big integer techique\n",
    "# function adapted from https://stackoverflow.com/a/5189881\n",
    "\n",
    "# Function to the big integer square root of s after multiplying by 10 raised to the 2 x digits.\n",
    "def sqrt2(s, digits):\n",
    "    s = s * (10**(2*digits))\n",
    "    approx = 0\n",
    "    better = 1 * (10**digits)\n",
    "    while better != approx:\n",
    "        approx = better\n",
    "        better = (approx + (s // approx)) >> 1\n",
    "    \n",
    "    # format result as a string adapted from https://stackoverflow.com/a/64278569    \n",
    "    print(f'The Square Root of 2 = {better // 10**100}.{better % 10**100:0100d}')\n",
    "    \n",
    "# find the square root of 2, to 100 digits\n",
    "sqrt2(2, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.8 SQRT2 Using Decimal Module\n",
    "I decided to verify the above answer using the python decimal module. The result of which is shown below. The result confirms the same result I got from sqrt2 function above (see 1.7 SQRT2 Using Big Integer Technique). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Square Root of 2 = 1.4142135623730950488016887242096980785696718753769480731766797379907324784621070388503875343276415727\n"
     ]
    }
   ],
   "source": [
    "# Python Function to calculate the square root of 2 using decimal module\n",
    "from decimal import *\n",
    "\n",
    "def sqrtv2(x0): \n",
    "    getcontext().prec = 101\n",
    "    # Change the precision to 100 decimal places: Adapted from https://docs.python.org/3/library/decimal.html\n",
    "    getcontext().rounding = ROUND_DOWN\n",
    "    # Round down the calculation when displaying 100 decimal places.\n",
    "    s = Decimal(2)\n",
    "    x = Decimal(x0) # initial guess\n",
    "    approx = x\n",
    "    # Improve the guess. Apply the formula x1 = (x0 + S / x0) / 2. The number x1 is a better approximation to sqrt(S).\n",
    "    better = (approx + s / approx) / 2\n",
    "    # Repeat the above steps until the required decimal expansion converges: using (xn+1 = (xn + S / xn) / 2) formula\n",
    "    while better != approx:\n",
    "        approx = better           \n",
    "        better = (approx + s / approx ) / 2       \n",
    "         \n",
    "    \n",
    "    print(\"The Square Root of 2 =\", approx)\n",
    "\n",
    "sqrtv2(1.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2 - Chi-squared Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this task, I created an algorithm using scipy.stats package to verify the value of the Chi-squared Test found in the Wikipedia article [1]. The Chi-squared test for independence is a statistical hypothesis test like a t-test. It is used to analyse whether two categorical variables are independent. The Wikipedia article gives the table below as an example [1], stating the Chi-squared value based on it is approximately 24.6 . "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Occupation   | A | B | C | D | Total\n",
    "-------------|---|---|---|---|------\n",
    "White collar | 90| 60|104| 95|\t349 \n",
    "Blue collar\t | 30| 50| 51| 20|\t151\n",
    "No collar\t | 30| 40| 45| 35|\t150\n",
    "-------------|---|---|---|---|------\n",
    "Total\t     |150|150|200|150|\t650\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A common problem in applied machine learning is determining whether input features are relevant to the outcome to be predicted.\n",
    "\n",
    "This is the problem of feature selection.\n",
    "\n",
    "In the case of classification problems where input variables are also categorical, we can use statistical tests to determine whether the output variable is dependent or independent of the input variables. If independent, then the input variable is a candidate for a feature that may be irrelevant to the problem and removed from the dataset.\n",
    "\n",
    "The Pearson’s chi-squared statistical hypothesis is an example of a test for independence between categorical variables.\n",
    "\n",
    "In this tutorial, you will discover the chi-squared statistical hypothesis test for quantifying the independence of pairs of categorical variables.\n",
    "\n",
    "After completing this tutorial, you will know:\n",
    "\n",
    "Pairs of categorical variables can be summarized using a contingency table.\n",
    "The chi-squared test can compare an observed contingency table to an expected table and determine if the categorical variables are independent.\n",
    "How to calculate and interpret the chi-squared test for categorical variables in Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pearson’s Chi-Squared Test\n",
    "The Pearson’s Chi-Squared test, or just Chi-Squared test for short, is named for Karl Pearson, although there are variations on the test.\n",
    "\n",
    "The Chi-Squared test is a statistical hypothesis test that assumes (the null hypothesis) that the observed frequencies for a categorical variable match the expected frequencies for the categorical variable. The test calculates a statistic that has a chi-squared distribution, named for the Greek capital letter Chi (X) pronounced “ki” as in kite.\n",
    "\n",
    "Given the Sex/Interest example above, the number of observations for a category (such as male and female) may or may not the same. Nevertheless, we can calculate the expected frequency of observations in each Interest group and see whether the partitioning of interests by Sex results in similar or different frequencies.\n",
    "\n",
    "The Chi-Squared test does this for a contingency table, first calculating the expected frequencies for the groups, then determining whether the division of the groups, called the observed frequencies, matches the expected frequencies.\n",
    "\n",
    "The result of the test is a test statistic that has a chi-squared distribution and can be interpreted to reject or fail to reject the assumption or null hypothesis that the observed and expected frequencies are the same.\n",
    "\n",
    "We can interpret the test statistic in the context of the chi-squared distribution with the requisite number of degress of freedom as follows:\n",
    "\n",
    "If Statistic >= Critical Value: significant result, reject null hypothesis (H0), dependent.\n",
    "If Statistic < Critical Value: not significant result, fail to reject null hypothesis (H0), independent.\n",
    "The degrees of freedom for the chi-squared distribution is calculated based on the size of the contingency table as:\n",
    "\n",
    "degrees of freedom: (rows - 1) * (cols - 1)\n",
    "1\n",
    "degrees of freedom: (rows - 1) * (cols - 1)\n",
    "In terms of a p-value and a chosen significance level (alpha), the test can be interpreted as follows:\n",
    "\n",
    "If p-value <= alpha: significant result, reject null hypothesis (H0), dependent.\n",
    "If p-value > alpha: not significant result, fail to reject null hypothesis (H0), independent.\n",
    "For the test to be effective, at least five observations are required in each cell of the contingency table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[90, 60, 104, 95], [30, 50, 51, 20], [30, 40, 45, 35]]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'dof' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-7b03ed970efc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# Calculate degrees of freedom (dof): (rows - 1) * (cols - 1)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'dof=%d'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mdof\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'dof' is not defined"
     ]
    }
   ],
   "source": [
    "# contingency table (Adapted from Brownlee , 2018))\n",
    "from scipy.stats import chi2_contingency\n",
    "from scipy.stats import chi2\n",
    "table = [[90, 60,104, 95],\n",
    "         [30, 50, 51, 20],\n",
    "         [30, 40, 45, 35]]\n",
    "print(table)\n",
    "# Calculate degrees of freedom (dof): (rows - 1) * (cols - 1)\n",
    "print('dof=%d' % dof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 80.53846154  80.53846154 107.38461538  80.53846154]\n",
      " [ 34.84615385  34.84615385  46.46153846  34.84615385]\n",
      " [ 34.61538462  34.61538462  46.15384615  34.61538462]]\n",
      "probability=0.950, critical=12.592, stat=24.57\n",
      "Dependent (reject H0)\n",
      "significance=0.050, p=0.000\n",
      "Dependent (reject H0)\n"
     ]
    }
   ],
   "source": [
    "# chi-squared test with similar proportions (Adapted from Brownlee , 2018))\n",
    "from scipy.stats import chi2_contingency\n",
    "from scipy.stats import chi2\n",
    "\n",
    "stat, p, dof, expected = chi2_contingency(table)\n",
    "\n",
    "print(expected)\n",
    "# interpret test-statistic\n",
    "prob = 0.95\n",
    "critical = chi2.ppf(prob, dof)\n",
    "print('probability=%.3f, critical=%.3f, stat=%.2f' % (prob, critical, stat))\n",
    "if abs(stat) >= critical:\n",
    "\tprint('Dependent (reject H0)')\n",
    "else:\n",
    "\tprint('Independent (fail to reject H0)')\n",
    "# interpret p-value\n",
    "alpha = 1.0 - prob\n",
    "print('significance=%.3f, p=%.3f' % (alpha, p))\n",
    "if p <= alpha:\n",
    "\tprint('Dependent (reject H0)')\n",
    "else:\n",
    "\tprint('Independent (fail to reject H0)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python for Data 25: Chi-Squared Tests "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(np.array([[90, 60, 104, 95, 349 ],[30, 50, 51, 20, 151],[30, 40, 45, 35, 150],[150, 150, 200, 150, 650]]),\n",
    "                   columns=['A', 'B', 'C','D', 'row_totals'],index=['White Collar','Blue Collar','No Collar', 'col_totals'])\n",
    "\n",
    "observed = df2.iloc[0:3,0:4]   # Get table without totals for later use\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected =  np.outer(df2[\"row_totals\"][0:3],\n",
    "                     df2.loc[\"col_totals\"][0:4]) / 650\n",
    "\n",
    "expected = pd.DataFrame(expected)\n",
    "\n",
    "expected.columns = ['A', 'B', 'C','D']\n",
    "expected.index = ['White Collar','Blue Collar','No Collar']\n",
    "\n",
    "expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi_squared_stat = (((observed-expected)**2)/expected).sum().sum()\n",
    "\n",
    "print(chi_squared_stat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crit = stats.chi2.ppf(q = 0.95, # Find the critical value for 95% confidence*\n",
    "                      df = 6)   # *\n",
    "\n",
    "print(\"Critical value\")\n",
    "print(crit)\n",
    "\n",
    "p_value = 1 - stats.chi2.cdf(x=chi_squared_stat,  # Find the p-value\n",
    "                             df=6)\n",
    "print(\"P value\")\n",
    "print(p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.chi2_contingency(observed= observed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output shows the chi-square statistic, the p-value and the degrees of freedom followed by the expected counts.\n",
    "\n",
    "As expected, given the high p-value, the test result does not detect a significant relationship between the variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3 - Analysis of Standard Deviation Functions used in Excel\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this task is to research excel standard deviation functions and explain which function gives a better estimate for the standard deviation of a population when performed on a sample.\n",
    "  1. In the first part of this task, I explain the difference between the two different versions of the standard deviation calculation found in Microsfot Excel; STDEV.P and STDEV.S. The standard deviation of an array of numbers x is calculated using numpy as np.sqrt(np.sum((x - np.mean(x)) * * 2)/len(x)) .The STDEV.P function performs this calculation but in the STDEV.S calculation the division is by len(x)-1 rather than len(x) . \n",
    "  1. In the second part of this task, I proceed to use numpy to perform a simulation, to demonstrate that the STDEV.S calculation is a better estimate for the standard deviation of a population when performed on a sample. I explain how I arrived at this conclusion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 STDEV.P\n",
    "The STDEV.P function is an Excel function used to calculate the population standard deviation. The function measures how much variance there is in a dataset of numbers compared to the average (mean) of the numbers in the dataset. The STDEV.P function is intended to be used to calculate the standard deviation of all of the elements from a data set. If dataset consists of a sample of the population, then the STDEV.S function should be used instead (Cheusava, 2020).\n",
    "\n",
    "![STDEV.P Formula](images/STDEVP.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 STDEV.S\n",
    "STDEV.S is an Excel function used to calculate the standard deviation of a sample set of data. Standard deviation is a measure of how much variance there is in a sample set of numbers compared to the average (mean) of the sample. It's calulated by getting the square root of; the sum differences between the mean and its data points, squared; divided by the number of data point minus one to correct for bias (Adapted from Hall 2020). This correction for bias is known as Bessel’s Correction, or n-1.\n",
    "\n",
    "According to Wikipedia, Bessel's correction makes use of n − 1 instead of n in the formula for sample standard deviation. This method is used to partially correct the bias in the estimation of the population standard deviation. \n",
    "![STDEV.S Formula](images/STDEVS.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Differences between STDEV.P and STDEV.S\n",
    "\n",
    "STDEV.P | STDEV.S\n",
    "------------ | -------------\n",
    "Data corresponds to the entire population | Data corresponds to a sample of the entire population\n",
    "The standard deviation is calculated using the \"n\" method | The standard deviation is calculated using the \"n-1\" method\n",
    "Does not correct Bias when used on sample of the population | Corrects Bias when used on sample of the entire population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STDEV.P Simulation\n",
    "\n",
    "# Create Dataset - this will simulate entire population of a dataset - adapted from Ebner 2019.\n",
    "\n",
    "# Import NumPy Library as np\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Generate ndarray of \"heights\" drawn from a sample of 10000 random numbers taken from a normal distribution \n",
    "# adapted from https://www.sharpsightlabs.com/blog/numpy-random-normal/\n",
    "\n",
    "# Define paramters\n",
    "loc = 177  # refers to mean adult male height in cms\n",
    "scale = 6.3 # refers to height standard deviation in cms\n",
    "size = 10000 # to generate 10000 values\n",
    "\n",
    "# Create an array using defined parameters using random.normal() function\n",
    "heights = [(np.random.normal(loc, scale , size))]\n",
    "pop = np.random.normal(loc, scale , size)\n",
    "\n",
    "#plot histogram using this data\n",
    "num_bins = 50 #number of bins used for histogram\n",
    "count, bins, ignored = plt.hist(heights, num_bins, density = False) \n",
    "\n",
    "# Plot Parameters\n",
    "plt.style.use('seaborn') # use seaborn theme\n",
    "plt.rcParams['figure.figsize'] = (12, 8) # resize the figure\n",
    "plt.xlabel('Height') # Create Label for x Axis\n",
    "plt.ylabel('Frequency') # Create Label for y Axis\n",
    "\n",
    "# Create Title for Plot - adding annotation for mean and standard deviation\n",
    "plt.title('Histogram of Heights: $\\mu=177.5$, $\\sigma=6.3$')\n",
    "plt.show() # show plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the standard deviation of array 'x' using numpy as np.sqrt(np.sum((x - np.mean(x))**2)/len(x))\n",
    "# Formula: Square root of; the sum differences between the mean and its data points, squared; \n",
    "#                          divided by the number of data points (Adapted from Hall 2020)\n",
    "stdevp = np.sqrt(np.sum((pop - np.mean(pop))**2)/len(pop))\n",
    "print('STDEV.P: ',stdevp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STDEV.S # Simulation 1 - Small Sample\n",
    "\n",
    "# Create random sample from dataset 'pop' to used with STDEV.S Function adapted from Geeksforgeeks 2018 \n",
    "# Generate 50 random integers from dataset 'x'\n",
    "sample1 = np.random.choice(pop,10)\n",
    "print(\"\\n Array 'sample1' filled with sample of 10 random numbers from numpy array 'pop' : \\n\", sample1); # print array "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the standard deviation of array 's' using numpy as np.sqrt(np.sum((x - np.mean(x))**2)/len(x-1))\n",
    "# Formula: Square root of; the sum differences between the mean and its data points, squared; \n",
    "#                          divided by the number of data points…minus one to correct for bias (Adapted from Hall 2020)\n",
    "stdevs = np.sqrt(np.sum((sample1 - np.mean(sample1))**2)/(len(sample1)-1))\n",
    "print('STDEV.S on Small Sample: ', stdevs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare STDEV.P & STDEV.S Simulation 1 - Small Sample\n",
    "\n",
    "# Use sample data and apply STDEV.P formula\n",
    "# Calculate the standard deviation of array 's' using numpy as np.sqrt(np.sum((x - np.mean(x))**2)/len(x))\n",
    "stdevp2 = np.sqrt(np.sum((sample1 - np.mean(sample1))**2)/len(sample1))\n",
    "print('STDEV.P: ',stdevp2,' STDEV.S: ', stdevs, ' Difference: ', stdevs-stdevp2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STDEV.S  Simulation 2 - Large Sample\n",
    "\n",
    "# Create ramdom sample from dataset 'x' to used with STDEV.S Function adapted from Geeksforgeeks 2018 \n",
    "# Generate 200 random integers from dataset 'x'\n",
    "sample2 = np.random.choice(pop,100)\n",
    "print(\"\\n Array 'sample2' filled with sample of 100 random numbers from numpy array 'pop' : \\n\", sample2); # print array  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the standard deviation of array 's2' using numpy as np.sqrt(np.sum((x - np.mean(x))**2)/len(x-1))\n",
    "stdevs2 = np.sqrt(np.sum((sample2 - np.mean(sample2))**2)/(len(sample2)-1))\n",
    "print('STDEV.S on Large Sample: ', stdevs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stdevp = np.sqrt(np.sum((s - np.mean(s))**2)/100)\n",
    "stdevs = np.sqrt(np.sum((s - np.mean(s))**2)/99)\n",
    "print('STDEV.P: ',stdevp,'STDEV.S: ', stdevs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare STDEV.P & STDEV.S Simulation 2 - Large Sample\n",
    "\n",
    "# Use sample data and apply STDEV.P formula\n",
    "# Calculate the standard deviation of array 'sample2' using numpy as np.sqrt(np.sum((x - np.mean(x))**2)/len(x))\n",
    "stdevp3 = np.sqrt(np.sum((sample2 - np.mean(sample2))**2)/len(sample2))\n",
    "print('STDEV.P: ',stdevp3,' STDEV.S: ', stdevs2, ' Difference: ', stdevs2-stdevp3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Conclusions\n",
    "* As the sample size increases the difference between STDEV.P and STDEV.S reduces, when calculated using the same sample dataset.  \n",
    "* In both scenarios the sample standard deviation was greater than the population standard deviation when calculated using the same sample dataset. \n",
    "* Proof that increasing sample size increases standard deviation, which converges to the true population standard deviation. Bessel's correction helps smaller samples get larger standard deviations than they would otherwise, hence n-1.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4 - Apply K-Means Clustering to Predict Flower Species in the Iris Data Set\n",
    "***\n",
    "Using scikit-learn, I apply k-means clustering to Fisher’s famous Iris data set. I explain how my code works and discuss it's accuracy. I go on to outline how my model could be used to make predictions of species of iris.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clustering is an unsupervisedlearning method that allows us to group set of objects based on similar characteristics. In general, it can help you find meaningful structure among your data, group similar data together and discover underlying patterns.\n",
    "\n",
    "One of the most common clustering methods is K-means algorithm. The goal of this algorithm isto partition the data into set such that the total sum of squared distances from each point to the mean point of the cluster is minimized.\n",
    "\n",
    "K means works through the following iterative process:\n",
    "\n",
    "    Pick a value for k (the number of clusters to create)\n",
    "    Initialize k ‘centroids’ (starting points) in your data\n",
    "    Create your clusters. Assign each point to the nearest centroid.\n",
    "    Make your clusters better. Move each centroid to the center of its cluster.\n",
    "    Repeat steps 3–4 until your centroids converge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For interacting with data sets.\n",
    "import pandas as pd\n",
    "\n",
    "# Numerical arrays.\n",
    "import numpy as np\n",
    "\n",
    "# Machine learning - KMeans.\n",
    "import sklearn.cluster as skcl\n",
    "\n",
    "# Plotting.\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import dataset\n",
    "from sklearn import datasets\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the iris data set from the library.\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "X = iris.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your target and predictors.\n",
    "X = iris.data[:, :2] # Select two features to use to predict cluster; sepal length & sepal width\n",
    "y = iris.target # This is the target output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the Data\n",
    "plt.scatter(X[:,0], X[:,1], c=y, cmap='gist_rainbow')\n",
    "plt.xlabel('Sepa1 Length', fontsize=18)\n",
    "plt.ylabel('Sepal Width', fontsize=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick a value for k (the number of clusters to create)\n",
    "km = skcl.KMeans(n_clusters = 3, n_jobs = 4, random_state=21)\n",
    "y_kmeans = km.fit_predict(X)\n",
    "y_kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize k ‘centroids’ (starting points) in your data\n",
    "centers = km.cluster_centers_\n",
    "\n",
    "print(centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualising the clusters\n",
    "\n",
    "plt.scatter(X[y_kmeans == 0, 0], X[y_kmeans == 0, 1], s = 150, c = 'red', label = 'Iris-setosa')\n",
    "plt.scatter(X[y_kmeans == 1, 0], X[y_kmeans == 1, 1], s = 150, c = 'blue', label = 'Iris-versicolour')\n",
    "plt.scatter(X[y_kmeans == 2, 0], X[y_kmeans == 2, 1], s = 150, c = 'green', label = 'Iris-virginica')\n",
    "\n",
    "#Plotting the centroids of the clusters\n",
    "plt.scatter(centers[:, 0], centers[:,1], s = 150, c = 'yellow', label = 'Centroids')\n",
    "\n",
    "plt.legend()\n",
    "plt.xlim([4, 8])\n",
    "plt.ylim([2, 4.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#this will tell us to which cluster does the data observations belong.\n",
    "new_labels = km.labels_# Plot the identified clusters and compare with the answers\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16,8))\n",
    "axes[0].scatter(X[:, 0], X[:, 1], c=y, cmap='gist_rainbow',edgecolor='k', s=150)\n",
    "axes[1].scatter(X[:, 0], X[:, 1], c=new_labels, cmap='jet',edgecolor='k', s=150)\n",
    "axes[0].set_xlabel('Sepal length', fontsize=18)\n",
    "axes[0].set_ylabel('Sepal width', fontsize=18)\n",
    "axes[1].set_xlabel('Sepal length', fontsize=18)\n",
    "axes[1].set_ylabel('Sepal width', fontsize=18)\n",
    "axes[0].tick_params(direction='in', length=10, width=5, colors='k', labelsize=20)\n",
    "axes[1].tick_params(direction='in', length=10, width=5, colors='k', labelsize=20)\n",
    "axes[0].set_title('Actual', fontsize=18)\n",
    "axes[1].set_title('Predicted', fontsize=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References:\n",
    "\n",
    "1. Wikipedia contributors *Square root of 2* [Online] Available at:https://en.wikipedia.org/wiki/Square_root_of_2 [Accessed 6 Oct 2020]\n",
    "1. Wikipedia contributors *Methods of computing square roots* [Online] Available at:https://en.wikipedia.org/wiki/Methods_of_computing_square_roots#Babylonian_method [Accessed 6 Oct 2020]\n",
    "1. Wikipedia contributors *Newton's method* [Online] Available at:https://en.wikipedia.org/wiki/Newton%27s_method [Accessed 6 Oct 2020]\n",
    "1. Wikipedia contributors *Irrational number* [Online] Available at:https://en.wikipedia.org/wiki/Irrational_number [Accessed 6 Oct 2020]\n",
    "1. Wiklin, R (2016) *The Babylonian method for finding square roots by hand* [Online] Available at:https://blogs.sas.com/content/iml/2016/05/16/babylonian-square-roots.html#:~:text=The%20Babylonian%20square%2Droot%20algorithm,Newton%20invented%20his%20general%20procedure. [Accessed 6 Oct 2020]\n",
    "1. Math.com (2012-2020) *Square roots* [Online] Available at:http://www.math.com/school/subject1/lessons/S1U1L9EX.html#sm1 [Accessed 6 Oct 2020]\n",
    "1. Python Software Foundation (2020) *Floating Point Arithmetic: Issues and Limitations* [Online] Available at:https://docs.python.org/3/tutorial/floatingpoint.html [Accessed 16 Oct 2020]\n",
    "1. Cross, D (2019) *How to Calculate a Million Digits of Pi* [Online] Available at:https://medium.com/@cosinekitty/how-to-calculate-a-million-digits-of-pi-d62ce3db8f58 [Accessed 21 Oct 2020]\n",
    "1. Python Software Foundation (2020) *Floating Point Arithmetic: Issues and Limitations* [Online] Available at:https://docs.python.org/3/tutorial/floatingpoint.html [Accessed 16 Oct 2020]\n",
    "1. Elkner, J Downey, A.B. & Meyers, C (2010) *Iteration* [Online] Available at:https://www.openbookproject.net/thinkcs/python/english2e/ch06.html [Accessed 7 Dec 2020]\n",
    "\n",
    "1. Wikipedia contributors *Chi-squared test* [Online] Available at:https://en.wikipedia.org/wiki/Chi-squared_test [Accessed 2 Nov 2020]\n",
    "1. Brownlee, J (2018) *A Gentle Introduction to the Chi-Squared Test for Machine Learning* [Online] Available at:https://machinelearningmastery.com/chi-squared-test-for-machine-learning/ [Accessed 02 Nov 2020]\n",
    "1. Hamel, G, J (2018) *Python for Data 25: Chi-Squared Tests* [Online] Available at:https://www.kaggle.com/hamelg/python-for-data-25-chi-squared-tests [Accessed 02 Nov 2020]\n",
    "1. Bruns, D (2012-2020) *Excel STDEV.S Function* [Online] Available at:https://exceljet.net/excel-functions/excel-stdev.p-function3 [Accessed 23 Nov 2020]\n",
    "1. Cheusava, S (2020) *How to calculate standard deviation in Excel* [Online] Available at:https://www.ablebits.com/office-addins-blog/2017/05/31/calculate-standard-deviation-excel/ [Accessed 23 Nov 2020]\n",
    "1. Ebner, J (2019) *HOW TO USE NUMPY RANDOM NORMAL IN PYTHON* [Online] Available at: https://www.sharpsightlabs.com/blog/numpy-random-normal/  [Accessed 23 Nov 2020]\n",
    "1. Geeksforgeeks (2018) *Python Numbers | choice() function* [Online] Available at:https://www.geeksforgeeks.org/python-numbers-choice-function/ [Accessed 23 Nov 2020]\n",
    "1. Hall, B (2020) *The Reasoning Behind Bessel’s Correction: n-1* [Online] Available at:https://towardsdatascience.com/the-reasoning-behind-bessels-correction-n-1-eeea25ec9bc9 [Accessed 23 Nov 2020]\n",
    "1. Wikipedia contributors (2020) *Bessel's correction* [Online] Available at:https://en.wikipedia.org/wiki/Bessel%27s_correction [Accessed 23 Nov 2020]\n",
    "1. Sanchez, B (2018) *PREDICTING IRIS FLOWER SPECIES WITH K-MEANS CLUSTERING IN PYTHON* [Online] Available at:https://medium.com/@belen.sanchez27/predicting-iris-flower-species-with-k-means-clustering-in-python-f6e46806aaee [Accessed 01 Dec 2020]\n",
    "1. Tim, I (2016) *Simple K-means clustering on the Iris dataset* [Online] Available at:https://www.kaggle.com/tonzowonzo/simple-k-means-clustering-on-the-iris-dataset [Accessed 01 Dec 2020]\n",
    "1. Dua, D. and Graff, C. (2019) UCI Machine Learning Repository *Iris Data Set* [Online] Available at:https://archive.ics.uci.edu/ml/datasets/Iris [Accessed 01 Dec 2020]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
